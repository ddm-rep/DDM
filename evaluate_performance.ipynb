{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import sys\n",
        "\n",
        "sys.path.append('/workspace')\n",
        "sys.path.append('/workspace/planner')\n",
        "\n",
        "from planner.modules.config_planner import ConfigPlanner\n",
        "from planner.modules.transformer import LatentPlanner\n",
        "from planner.modules.dataset_lowres import LowResVideoDataset\n",
        "from models.diffusion import AsymmetricUNet\n",
        "from models.scheduler import NoiseScheduler\n",
        "\n",
        "print(\"Imports completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_mse(pred: torch.Tensor, gt: torch.Tensor) -> float:\n",
        "    return float(F.mse_loss(pred, gt).item())\n",
        "\n",
        "\n",
        "def compute_mae(pred: torch.Tensor, gt: torch.Tensor) -> float:\n",
        "    return float(F.l1_loss(pred, gt).item())\n",
        "\n",
        "\n",
        "def compute_psnr(pred: torch.Tensor, gt: torch.Tensor, max_val: float = 2.0) -> float:\n",
        "    mse = F.mse_loss(pred, gt).item()\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    psnr = 10 * np.log10((max_val ** 2) / mse)\n",
        "    return float(psnr)\n",
        "\n",
        "\n",
        "def compute_ssim(pred: torch.Tensor, gt: torch.Tensor, window_size: int = 11) -> float:\n",
        "    pred_norm = (pred + 1.0) * 0.5\n",
        "    gt_norm = (gt + 1.0) * 0.5\n",
        "    \n",
        "    if pred_norm.ndim == 4:\n",
        "        pred_gray = pred_norm.mean(dim=1)  # [B, H, W]\n",
        "        gt_gray = gt_norm.mean(dim=1)\n",
        "    else:\n",
        "        pred_gray = pred_norm.mean(dim=0)  # [H, W]\n",
        "        gt_gray = gt_norm.mean(dim=0)\n",
        "    \n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "    \n",
        "    mu_pred = pred_gray.mean()\n",
        "    mu_gt = gt_gray.mean()\n",
        "    \n",
        "    sigma_pred_sq = ((pred_gray - mu_pred) ** 2).mean()\n",
        "    sigma_gt_sq = ((gt_gray - mu_gt) ** 2).mean()\n",
        "    sigma_pred_gt = ((pred_gray - mu_pred) * (gt_gray - mu_gt)).mean()\n",
        "    \n",
        "    numerator = (2 * mu_pred * mu_gt + C1) * (2 * sigma_pred_gt + C2)\n",
        "    denominator = (mu_pred ** 2 + mu_gt ** 2 + C1) * (sigma_pred_sq + sigma_gt_sq + C2)\n",
        "    \n",
        "    ssim = numerator / (denominator + 1e-8)\n",
        "    return float(ssim.clamp(0, 1).item())\n",
        "\n",
        "\n",
        "def extract_ball_position(frame: np.ndarray, threshold: float = 0.7) -> Optional[Tuple[float, float]]:\n",
        "    if len(frame.shape) == 3:\n",
        "        gray = np.mean(frame, axis=2).astype(np.float32) / 255.0\n",
        "    else:\n",
        "        gray = frame.astype(np.float32)\n",
        "        if gray.max() > 1.0:\n",
        "            gray = gray / 255.0\n",
        "    \n",
        "    mask = gray > threshold\n",
        "    \n",
        "    if not np.any(mask):\n",
        "        max_idx = np.unravel_index(np.argmax(gray), gray.shape)\n",
        "        return (float(max_idx[0]), float(max_idx[1]))\n",
        "    \n",
        "    y_coords, x_coords = np.where(mask)\n",
        "    if len(y_coords) == 0:\n",
        "        return None\n",
        "    \n",
        "    weights = gray[y_coords, x_coords]\n",
        "    total_weight = np.sum(weights)\n",
        "    \n",
        "    if total_weight > 0:\n",
        "        y_center = np.average(y_coords, weights=weights)\n",
        "        x_center = np.average(x_coords, weights=weights)\n",
        "    else:\n",
        "        y_center = np.mean(y_coords)\n",
        "        x_center = np.mean(x_coords)\n",
        "    \n",
        "    return (float(y_center), float(x_center))\n",
        "\n",
        "\n",
        "def compute_trajectory_error(\n",
        "    pred_video: torch.Tensor,\n",
        "    gt_video: torch.Tensor,\n",
        "    threshold: float = 0.7\n",
        ") -> Dict[str, float]:\n",
        "    def to_uint8(tensor):\n",
        "        tensor = tensor.clamp(-1, 1)\n",
        "        tensor = (tensor + 1) * 0.5\n",
        "        tensor = (tensor * 255.0).round().to(torch.uint8)\n",
        "        return tensor\n",
        "    \n",
        "    if pred_video.ndim == 4:\n",
        "        pred_video = pred_video.unsqueeze(0)\n",
        "        gt_video = gt_video.unsqueeze(0)\n",
        "    \n",
        "    B, T, C, H, W = pred_video.shape\n",
        "    errors = []\n",
        "    valid_frames = 0\n",
        "    \n",
        "    for b in range(B):\n",
        "        for t in range(T):\n",
        "            pred_frame = to_uint8(pred_video[b, t]).permute(1, 2, 0).cpu().numpy()  # [H, W, 3]\n",
        "            gt_frame = to_uint8(gt_video[b, t]).permute(1, 2, 0).cpu().numpy()\n",
        "            \n",
        "            pred_pos = extract_ball_position(pred_frame, threshold)\n",
        "            gt_pos = extract_ball_position(gt_frame, threshold)\n",
        "            \n",
        "            if pred_pos is not None and gt_pos is not None:\n",
        "                error = np.sqrt((pred_pos[0] - gt_pos[0])**2 + (pred_pos[1] - gt_pos[1])**2)\n",
        "                errors.append(error)\n",
        "                valid_frames += 1\n",
        "    \n",
        "    if len(errors) == 0:\n",
        "        return {'mean': float('nan'), 'std': float('nan'), 'max': float('nan')}\n",
        "    \n",
        "    errors = np.array(errors)\n",
        "    return {\n",
        "        'mean': float(errors.mean()),\n",
        "        'std': float(errors.std()),\n",
        "        'max': float(errors.max())\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_temporal_consistency(video: torch.Tensor) -> float:\n",
        "    if video.ndim == 4:\n",
        "        video = video.unsqueeze(0)\n",
        "    \n",
        "    B, T, C, H, W = video.shape\n",
        "    if T < 2:\n",
        "        return 0.0\n",
        "    \n",
        "    diffs = []\n",
        "    for b in range(B):\n",
        "        for t in range(1, T):\n",
        "            diff = F.l1_loss(video[b, t], video[b, t-1]).item()\n",
        "            diffs.append(diff)\n",
        "    \n",
        "    return float(np.mean(diffs)) if diffs else 0.0\n",
        "\n",
        "\n",
        "print(\"Metric functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_resolution_for_timestep(\n",
        "    t: int, num_timesteps: int, high_res: int, latent_res: int, k_step: int\n",
        ") -> int:\n",
        "    ratio = t / (num_timesteps - 1)\n",
        "    size_float = high_res - ratio * (high_res - latent_res)\n",
        "    size_int = int(round(size_float / k_step) * k_step)\n",
        "    size_int = max(latent_res, min(high_res, size_int))\n",
        "    return size_int\n",
        "\n",
        "\n",
        "def planner_generate(\n",
        "    planner: LatentPlanner,\n",
        "    cond_frames: torch.Tensor,\n",
        "    total_T: int,\n",
        "    device: torch.device,\n",
        "    show_progress: bool = False\n",
        ") -> torch.Tensor:\n",
        "    planner.eval()\n",
        "    B, cond_T, C, H, W = cond_frames.shape\n",
        "    frames = [cond_frames[:, i] for i in range(cond_T)]\n",
        "    \n",
        "    iterator = range(total_T - cond_T)\n",
        "    if show_progress:\n",
        "        iterator = tqdm(iterator, desc=\"  Planner generating\", leave=False)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in iterator:\n",
        "            seq = torch.stack(frames, dim=1)  # [B, t, C, H, W]\n",
        "            attn = torch.ones(B, seq.shape[1], device=device)\n",
        "            pred = planner(seq, attn_mask=attn)  # [B, t+1, C, H, W]\n",
        "            next_frame = pred[:, seq.shape[1]]  # prediction for f_t\n",
        "            frames.append(next_frame)\n",
        "    \n",
        "    return torch.stack(frames, dim=1)\n",
        "\n",
        "\n",
        "def refiner_refine_sequence(\n",
        "    refiner: AsymmetricUNet,\n",
        "    scheduler: NoiseScheduler,\n",
        "    lowres_btchw: torch.Tensor,\n",
        "    high_res: int = 128,\n",
        "    latent_res: int = 32,\n",
        "    k_step: int = 1,\n",
        "    t_start_frac: float = 0.1,\n",
        "    batch_frames: bool = True,\n",
        ") -> torch.Tensor:\n",
        "    refiner.eval()\n",
        "    B, T, C, H, W = lowres_btchw.shape\n",
        "    assert H == latent_res and W == latent_res\n",
        "    \n",
        "    t_start = int((scheduler.num_timesteps - 1) * float(t_start_frac))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        if batch_frames:\n",
        "            out_frames_list = []\n",
        "            \n",
        "            for b_idx in range(B):\n",
        "                latent_video = lowres_btchw[b_idx]  # [T, 3, 32, 32]\n",
        "                \n",
        "                noise = torch.randn_like(latent_video)\n",
        "                timesteps = torch.full((T,), t_start, device=latent_video.device, dtype=torch.long)\n",
        "                curr = scheduler.add_noise(latent_video, noise, timesteps)\n",
        "                \n",
        "                for t in range(t_start, -1, -1):\n",
        "                    t_batch = torch.full((T,), t, device=latent_video.device, dtype=torch.long)\n",
        "                    target_res_t = get_resolution_for_timestep(\n",
        "                        t, scheduler.num_timesteps, high_res, latent_res, k_step\n",
        "                    )\n",
        "                    \n",
        "                    curr_h, curr_w = curr.shape[-2:]\n",
        "                    if curr_h != target_res_t or curr_w != target_res_t:\n",
        "                        curr = F.interpolate(\n",
        "                            curr, size=(target_res_t, target_res_t),\n",
        "                            mode='bilinear', align_corners=False\n",
        "                        )\n",
        "                        curr_h, curr_w = target_res_t, target_res_t\n",
        "                    \n",
        "                    pred_x0_high = refiner(curr, t_batch, target_shape=(high_res, high_res))\n",
        "                    pred_x0_curr = F.interpolate(\n",
        "                        pred_x0_high, size=(curr_h, curr_w),\n",
        "                        mode='bilinear', align_corners=False\n",
        "                    )\n",
        "                    \n",
        "                    t_val = int(t)\n",
        "                    prev = scheduler.step_x0(pred_x0_curr, t_val, curr)\n",
        "                    \n",
        "                    if t > 0:\n",
        "                        next_res = get_resolution_for_timestep(\n",
        "                            t - 1, scheduler.num_timesteps, high_res, latent_res, k_step\n",
        "                        )\n",
        "                        if prev.shape[-1] != next_res or prev.shape[-2] != next_res:\n",
        "                            curr = F.interpolate(\n",
        "                                prev, size=(next_res, next_res),\n",
        "                                mode='bilinear', align_corners=False\n",
        "                            )\n",
        "                        else:\n",
        "                            curr = prev\n",
        "                    else:\n",
        "                        curr = prev\n",
        "                \n",
        "                if curr.shape[-1] != high_res or curr.shape[-2] != high_res:\n",
        "                    curr = F.interpolate(\n",
        "                        curr, size=(high_res, high_res),\n",
        "                        mode='bilinear', align_corners=False\n",
        "                    )\n",
        "                \n",
        "                out_frames_list.append(curr)\n",
        "            \n",
        "            return torch.stack(out_frames_list, dim=0)\n",
        "        else:\n",
        "            out_frames = []\n",
        "            for i in range(T):\n",
        "                latent_img = lowres_btchw[:, i]  # [B, 3, 32, 32]\n",
        "                \n",
        "                noise = torch.randn_like(latent_img)\n",
        "                timesteps = torch.full((B,), t_start, device=latent_img.device, dtype=torch.long)\n",
        "                curr = scheduler.add_noise(latent_img, noise, timesteps)\n",
        "                \n",
        "                for t in range(t_start, -1, -1):\n",
        "                    t_batch = torch.full((B,), t, device=latent_img.device, dtype=torch.long)\n",
        "                    target_res_t = get_resolution_for_timestep(\n",
        "                        t, scheduler.num_timesteps, high_res, latent_res, k_step\n",
        "                    )\n",
        "                    \n",
        "                    if curr.shape[-1] != target_res_t:\n",
        "                        curr = F.interpolate(\n",
        "                            curr, size=(target_res_t, target_res_t),\n",
        "                            mode='bilinear', align_corners=False\n",
        "                        )\n",
        "                    \n",
        "                    pred_x0_high = refiner(curr, t_batch, target_shape=(high_res, high_res))\n",
        "                    pred_x0_curr = F.interpolate(\n",
        "                        pred_x0_high, size=(target_res_t, target_res_t),\n",
        "                        mode='bilinear', align_corners=False\n",
        "                    )\n",
        "                    \n",
        "                    prev = scheduler.step_x0(pred_x0_curr, t_batch, curr)\n",
        "                    \n",
        "                    if t > 0:\n",
        "                        next_res = get_resolution_for_timestep(\n",
        "                            t - 1, scheduler.num_timesteps, high_res, latent_res, k_step\n",
        "                        )\n",
        "                        if prev.shape[-1] != next_res:\n",
        "                            curr = F.interpolate(\n",
        "                                prev, size=(next_res, next_res),\n",
        "                                mode='bilinear', align_corners=False\n",
        "                            )\n",
        "                        else:\n",
        "                            curr = prev\n",
        "                    else:\n",
        "                        curr = prev\n",
        "                \n",
        "                if curr.shape[-1] != high_res:\n",
        "                    curr = F.interpolate(\n",
        "                        curr, size=(high_res, high_res),\n",
        "                        mode='bilinear', align_corners=False\n",
        "                    )\n",
        "                \n",
        "                out_frames.append(curr)\n",
        "            \n",
        "            return torch.stack(out_frames, dim=1)\n",
        "\n",
        "\n",
        "print(\"Helper functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Config (EDIT ONLY THIS CELL) ======\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# --- Checkpoints ---\n",
        "PLANNER_CKPT = '/workspace/planner/experiments/20260123_073354_planner_32_large/checkpoints/model_epoch_1000.pth'\n",
        "REFINER_CKPT = '/workspace/experiments/20260120_100656_obj_weight_5/checkpoints/model_epoch_30.pt'\n",
        "\n",
        "# --- Data ---\n",
        "LOWRES_ROOT = '/workspace/data/processed_32'  # must be 32x32 .pt\n",
        "HIGHRES_ROOT = '/workspace/data/processed'   # 128x128 high-res data (optional)\n",
        "SPLIT = 'val'  # 'train', 'val', 'test'\n",
        "\n",
        "EVAL_MODE = 'all'\n",
        "COND_FRAMES_LIST = [1,3,5,10,15]\n",
        "MAX_SAMPLES = 1\n",
        "\n",
        "# --- Resolutions / schedule ---\n",
        "LATENT_RES = 32\n",
        "HIGH_RES = 128\n",
        "K_STEP = 1\n",
        "\n",
        "# --- Refiner sampling strength ---\n",
        "T_START_FRAC = 0.1\n",
        "REFINER_BATCH_FRAMES = True\n",
        "\n",
        "# --- Refiner model architecture (must match the checkpoint) ---\n",
        "REF_MODEL_CHANNELS = 128\n",
        "REF_CHANNEL_MULT = (1, 2, 4, 8)\n",
        "REF_NUM_RES_BLOCKS = 2\n",
        "\n",
        "# --- Outputs ---\n",
        "OUTPUT_DIR = '/workspace/evaluation_results'\n",
        "\n",
        "print('DEVICE:', DEVICE)\n",
        "print('LOWRES_ROOT:', LOWRES_ROOT)\n",
        "print('SPLIT:', SPLIT)\n",
        "print('EVAL_MODE:', EVAL_MODE)\n",
        "print('COND_FRAMES_LIST:', COND_FRAMES_LIST)\n",
        "print('OUTPUT_DIR:', OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_planner(\n",
        "    planner: LatentPlanner,\n",
        "    dataloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    cond_frames: int = 5,\n",
        "    max_samples: Optional[int] = None\n",
        ") -> Dict[str, List[float]]:\n",
        "    planner.eval()\n",
        "    \n",
        "    all_metrics = {\n",
        "        'mse': [], 'mae': [], 'psnr': [], 'ssim': [],\n",
        "        'trajectory_error': [],\n",
        "        'temporal_consistency_pred': [],\n",
        "        'temporal_consistency_gt': []\n",
        "    }\n",
        "    \n",
        "    sample_count = 0\n",
        "    \n",
        "    total_samples = min(len(dataloader), max_samples) if max_samples else len(dataloader)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc=\"Evaluating Planner\", total=total_samples, miniters=1, mininterval=1.0)\n",
        "        \n",
        "        for batch in pbar:\n",
        "            if max_samples and sample_count >= max_samples:\n",
        "                break\n",
        "            \n",
        "            seq = batch[\"seq\"].to(device)\n",
        "            lengths = batch[\"lengths\"]\n",
        "            \n",
        "            B = seq.shape[0]\n",
        "            for b in range(B):\n",
        "                if max_samples and sample_count >= max_samples:\n",
        "                    break\n",
        "                \n",
        "                T_actual = int(lengths[b].item())\n",
        "                if T_actual < cond_frames + 1:\n",
        "                    continue\n",
        "                \n",
        "                pbar.set_postfix({\n",
        "                    'sample': sample_count + 1,\n",
        "                    'frames': T_actual,\n",
        "                    'cond': cond_frames\n",
        "                })\n",
        "                \n",
        "                cond_seq = seq[b:b+1, :cond_frames]\n",
        "                target_seq = seq[b:b+1, :T_actual]\n",
        "                \n",
        "                pred_seq = planner_generate(planner, cond_seq, T_actual, device, show_progress=False)\n",
        "                \n",
        "                pred_eval = pred_seq[:, cond_frames:]\n",
        "                target_eval = target_seq[:, cond_frames:]\n",
        "                \n",
        "                T_eval = pred_eval.shape[1]\n",
        "                frame_metrics = {'mse': [], 'mae': [], 'psnr': [], 'ssim': []}\n",
        "                \n",
        "                for t in range(T_eval):\n",
        "                    pred_frame = pred_eval[0, t]\n",
        "                    target_frame = target_eval[0, t]\n",
        "                    \n",
        "                    frame_metrics['mse'].append(compute_mse(pred_frame, target_frame))\n",
        "                    frame_metrics['mae'].append(compute_mae(pred_frame, target_frame))\n",
        "                    frame_metrics['psnr'].append(compute_psnr(pred_frame, target_frame))\n",
        "                    frame_metrics['ssim'].append(compute_ssim(pred_frame, target_frame))\n",
        "                \n",
        "                all_metrics['mse'].append(np.mean(frame_metrics['mse']))\n",
        "                all_metrics['mae'].append(np.mean(frame_metrics['mae']))\n",
        "                all_metrics['psnr'].append(np.mean(frame_metrics['psnr']))\n",
        "                all_metrics['ssim'].append(np.mean(frame_metrics['ssim']))\n",
        "                \n",
        "                traj_err = compute_trajectory_error(pred_eval, target_eval)\n",
        "                all_metrics['trajectory_error'].append(traj_err['mean'])\n",
        "                \n",
        "                all_metrics['temporal_consistency_pred'].append(\n",
        "                    compute_temporal_consistency(pred_eval)\n",
        "                )\n",
        "                all_metrics['temporal_consistency_gt'].append(\n",
        "                    compute_temporal_consistency(target_eval)\n",
        "                )\n",
        "                \n",
        "                sample_count += 1\n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "\n",
        "def evaluate_refiner(\n",
        "    refiner: AsymmetricUNet,\n",
        "    scheduler: NoiseScheduler,\n",
        "    lowres_dataloader: DataLoader,\n",
        "    highres_dataloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    high_res: int = 128,\n",
        "    latent_res: int = 32,\n",
        "    k_step: int = 1,\n",
        "    t_start_frac: float = 0.1,\n",
        "    batch_frames: bool = True,\n",
        "    max_samples: Optional[int] = None\n",
        ") -> Dict[str, List[float]]:\n",
        "    refiner.eval()\n",
        "    \n",
        "    all_metrics = {\n",
        "        'mse': [], 'mae': [], 'psnr': [], 'ssim': [],\n",
        "        'trajectory_error': [],\n",
        "        'temporal_consistency_pred': [],\n",
        "        'temporal_consistency_gt': []\n",
        "    }\n",
        "    \n",
        "    sample_count = 0\n",
        "    \n",
        "    total_samples = min(len(lowres_dataloader), max_samples) if max_samples else len(lowres_dataloader)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(\n",
        "            zip(lowres_dataloader, highres_dataloader),\n",
        "            desc=\"Evaluating Refiner\",\n",
        "            total=total_samples,\n",
        "            miniters=1,\n",
        "            mininterval=1.0\n",
        "        )\n",
        "        \n",
        "        for (lowres_batch, highres_batch) in pbar:\n",
        "            if max_samples and sample_count >= max_samples:\n",
        "                break\n",
        "            \n",
        "            lowres_seq = lowres_batch[\"seq\"].to(device)\n",
        "            highres_seq = highres_batch[\"seq\"].to(device)\n",
        "            lengths = lowres_batch[\"lengths\"]\n",
        "            \n",
        "            B = lowres_seq.shape[0]\n",
        "            for b in range(B):\n",
        "                if max_samples and sample_count >= max_samples:\n",
        "                    break\n",
        "                \n",
        "                T_actual = int(lengths[b].item())\n",
        "                \n",
        "                pbar.set_postfix({\n",
        "                    'sample': sample_count + 1,\n",
        "                    'frames': T_actual\n",
        "                })\n",
        "                \n",
        "                lowres_video = lowres_seq[b:b+1, :T_actual]\n",
        "                highres_gt = highres_seq[b:b+1, :T_actual]\n",
        "                \n",
        "                if highres_gt.shape[-1] != high_res:\n",
        "                    B_dim, T, C, H, W = highres_gt.shape\n",
        "                    highres_gt_flat = highres_gt.reshape(B_dim * T * C, 1, H, W)\n",
        "                    highres_gt_upscaled = F.interpolate(\n",
        "                        highres_gt_flat,\n",
        "                        size=(high_res, high_res),\n",
        "                        mode='bilinear',\n",
        "                        align_corners=False\n",
        "                    )\n",
        "                    highres_gt = highres_gt_upscaled.reshape(B_dim, T, C, high_res, high_res)\n",
        "                \n",
        "                highres_pred = refiner_refine_sequence(\n",
        "                    refiner, scheduler, lowres_video,\n",
        "                    high_res=high_res, latent_res=latent_res,\n",
        "                    k_step=k_step, t_start_frac=t_start_frac,\n",
        "                    batch_frames=batch_frames\n",
        "                )\n",
        "                \n",
        "                T = highres_pred.shape[1]\n",
        "                frame_metrics = {'mse': [], 'mae': [], 'psnr': [], 'ssim': []}\n",
        "                \n",
        "                for t in range(T):\n",
        "                    pred_frame = highres_pred[0, t]\n",
        "                    gt_frame = highres_gt[0, t]\n",
        "                    \n",
        "                    frame_metrics['mse'].append(compute_mse(pred_frame, gt_frame))\n",
        "                    frame_metrics['mae'].append(compute_mae(pred_frame, gt_frame))\n",
        "                    frame_metrics['psnr'].append(compute_psnr(pred_frame, gt_frame))\n",
        "                    frame_metrics['ssim'].append(compute_ssim(pred_frame, gt_frame))\n",
        "                \n",
        "                all_metrics['mse'].append(np.mean(frame_metrics['mse']))\n",
        "                all_metrics['mae'].append(np.mean(frame_metrics['mae']))\n",
        "                all_metrics['psnr'].append(np.mean(frame_metrics['psnr']))\n",
        "                all_metrics['ssim'].append(np.mean(frame_metrics['ssim']))\n",
        "                \n",
        "                traj_err = compute_trajectory_error(highres_pred, highres_gt)\n",
        "                all_metrics['trajectory_error'].append(traj_err['mean'])\n",
        "                \n",
        "                all_metrics['temporal_consistency_pred'].append(\n",
        "                    compute_temporal_consistency(highres_pred)\n",
        "                )\n",
        "                all_metrics['temporal_consistency_gt'].append(\n",
        "                    compute_temporal_consistency(highres_gt)\n",
        "                )\n",
        "                \n",
        "                sample_count += 1\n",
        "                pbar.update(1)\n",
        "    \n",
        "    pbar.close()\n",
        "    return all_metrics\n",
        "\n",
        "\n",
        "def evaluate_end2end(\n",
        "    planner: LatentPlanner,\n",
        "    refiner: AsymmetricUNet,\n",
        "    scheduler: NoiseScheduler,\n",
        "    lowres_dataloader: DataLoader,\n",
        "    highres_dataloader: DataLoader,\n",
        "    device: torch.device,\n",
        "    cond_frames: int = 5,\n",
        "    high_res: int = 128,\n",
        "    latent_res: int = 32,\n",
        "    k_step: int = 1,\n",
        "    t_start_frac: float = 0.1,\n",
        "    batch_frames: bool = True,\n",
        "    max_samples: Optional[int] = None\n",
        ") -> Dict[str, List[float]]:\n",
        "    planner.eval()\n",
        "    refiner.eval()\n",
        "    \n",
        "    all_metrics = {\n",
        "        'mse': [], 'mae': [], 'psnr': [], 'ssim': [],\n",
        "        'trajectory_error': [],\n",
        "        'temporal_consistency_pred': [],\n",
        "        'temporal_consistency_gt': []\n",
        "    }\n",
        "    \n",
        "    planner_metrics = {\n",
        "        'mse': [], 'mae': [], 'psnr': [], 'ssim': [],\n",
        "        'trajectory_error': []\n",
        "    }\n",
        "    \n",
        "    refiner_metrics = {\n",
        "        'mse': [], 'mae': [], 'psnr': [], 'ssim': [],\n",
        "        'trajectory_error': []\n",
        "    }\n",
        "    \n",
        "    sample_count = 0\n",
        "    \n",
        "    total_samples = min(len(lowres_dataloader), max_samples) if max_samples else len(lowres_dataloader)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(\n",
        "            zip(lowres_dataloader, highres_dataloader),\n",
        "            desc=\"Evaluating End-to-End\",\n",
        "            total=total_samples,\n",
        "            miniters=1,\n",
        "            mininterval=1.0\n",
        "        )\n",
        "        \n",
        "        for (lowres_batch, highres_batch) in pbar:\n",
        "            if max_samples and sample_count >= max_samples:\n",
        "                break\n",
        "            \n",
        "            lowres_seq = lowres_batch[\"seq\"].to(device)\n",
        "            highres_seq = highres_batch[\"seq\"].to(device)\n",
        "            lengths = lowres_batch[\"lengths\"]\n",
        "            \n",
        "            B = lowres_seq.shape[0]\n",
        "            for b in range(B):\n",
        "                if max_samples and sample_count >= max_samples:\n",
        "                    break\n",
        "                \n",
        "                T_actual = int(lengths[b].item())\n",
        "                if T_actual < cond_frames + 1:\n",
        "                    continue\n",
        "                \n",
        "                pbar.set_postfix({\n",
        "                    'sample': sample_count + 1,\n",
        "                    'frames': T_actual,\n",
        "                    'cond': cond_frames\n",
        "                })\n",
        "                \n",
        "                cond_seq = lowres_seq[b:b+1, :cond_frames]\n",
        "                \n",
        "                lowres_gt = lowres_seq[b:b+1, :T_actual]\n",
        "                highres_gt = highres_seq[b:b+1, :T_actual]\n",
        "                \n",
        "                if highres_gt.shape[-1] != high_res:\n",
        "                    B_dim, T, C, H, W = highres_gt.shape\n",
        "                    highres_gt_flat = highres_gt.reshape(B_dim * T * C, 1, H, W)\n",
        "                    highres_gt_upscaled = F.interpolate(\n",
        "                        highres_gt_flat,\n",
        "                        size=(high_res, high_res),\n",
        "                        mode='bilinear',\n",
        "                        align_corners=False\n",
        "                    )\n",
        "                    highres_gt = highres_gt_upscaled.reshape(B_dim, T, C, high_res, high_res)\n",
        "                \n",
        "                lowres_pred = planner_generate(planner, cond_seq, T_actual, device, show_progress=False)\n",
        "                \n",
        "                planner_pred_eval = lowres_pred[:, cond_frames:]\n",
        "                planner_gt_eval = lowres_gt[:, cond_frames:]\n",
        "                \n",
        "                T_eval = planner_pred_eval.shape[1]\n",
        "                planner_frame_metrics = {'mse': [], 'mae': [], 'psnr': [], 'ssim': []}\n",
        "                \n",
        "                for t in range(T_eval):\n",
        "                    pred_frame = planner_pred_eval[0, t]\n",
        "                    gt_frame = planner_gt_eval[0, t]\n",
        "                    \n",
        "                    planner_frame_metrics['mse'].append(compute_mse(pred_frame, gt_frame))\n",
        "                    planner_frame_metrics['mae'].append(compute_mae(pred_frame, gt_frame))\n",
        "                    planner_frame_metrics['psnr'].append(compute_psnr(pred_frame, gt_frame))\n",
        "                    planner_frame_metrics['ssim'].append(compute_ssim(pred_frame, gt_frame))\n",
        "                \n",
        "                planner_metrics['mse'].append(np.mean(planner_frame_metrics['mse']))\n",
        "                planner_metrics['mae'].append(np.mean(planner_frame_metrics['mae']))\n",
        "                planner_metrics['psnr'].append(np.mean(planner_frame_metrics['psnr']))\n",
        "                planner_metrics['ssim'].append(np.mean(planner_frame_metrics['ssim']))\n",
        "                \n",
        "                planner_traj_err = compute_trajectory_error(planner_pred_eval, planner_gt_eval)\n",
        "                planner_metrics['trajectory_error'].append(planner_traj_err['mean'])\n",
        "                \n",
        "                highres_from_gt_lowres = refiner_refine_sequence(\n",
        "                    refiner, scheduler, lowres_gt,\n",
        "                    high_res=high_res, latent_res=latent_res,\n",
        "                    k_step=k_step, t_start_frac=t_start_frac,\n",
        "                    batch_frames=batch_frames\n",
        "                )\n",
        "                \n",
        "                refiner_pred_eval = highres_from_gt_lowres[:, cond_frames:]\n",
        "                refiner_gt_eval = highres_gt[:, cond_frames:]\n",
        "                \n",
        "                refiner_frame_metrics = {'mse': [], 'mae': [], 'psnr': [], 'ssim': []}\n",
        "                \n",
        "                for t in range(T_eval):\n",
        "                    pred_frame = refiner_pred_eval[0, t]\n",
        "                    gt_frame = refiner_gt_eval[0, t]\n",
        "                    \n",
        "                    refiner_frame_metrics['mse'].append(compute_mse(pred_frame, gt_frame))\n",
        "                    refiner_frame_metrics['mae'].append(compute_mae(pred_frame, gt_frame))\n",
        "                    refiner_frame_metrics['psnr'].append(compute_psnr(pred_frame, gt_frame))\n",
        "                    refiner_frame_metrics['ssim'].append(compute_ssim(pred_frame, gt_frame))\n",
        "                \n",
        "                refiner_metrics['mse'].append(np.mean(refiner_frame_metrics['mse']))\n",
        "                refiner_metrics['mae'].append(np.mean(refiner_frame_metrics['mae']))\n",
        "                refiner_metrics['psnr'].append(np.mean(refiner_frame_metrics['psnr']))\n",
        "                refiner_metrics['ssim'].append(np.mean(refiner_frame_metrics['ssim']))\n",
        "                \n",
        "                refiner_traj_err = compute_trajectory_error(refiner_pred_eval, refiner_gt_eval)\n",
        "                refiner_metrics['trajectory_error'].append(refiner_traj_err['mean'])\n",
        "                \n",
        "                highres_pred = refiner_refine_sequence(\n",
        "                    refiner, scheduler, lowres_pred,\n",
        "                    high_res=high_res, latent_res=latent_res,\n",
        "                    k_step=k_step, t_start_frac=t_start_frac,\n",
        "                    batch_frames=batch_frames\n",
        "                )\n",
        "                \n",
        "                e2e_pred_eval = highres_pred[:, cond_frames:]\n",
        "                e2e_gt_eval = highres_gt[:, cond_frames:]\n",
        "                \n",
        "                e2e_frame_metrics = {'mse': [], 'mae': [], 'psnr': [], 'ssim': []}\n",
        "                \n",
        "                for t in range(T_eval):\n",
        "                    pred_frame = e2e_pred_eval[0, t]\n",
        "                    gt_frame = e2e_gt_eval[0, t]\n",
        "                    \n",
        "                    e2e_frame_metrics['mse'].append(compute_mse(pred_frame, gt_frame))\n",
        "                    e2e_frame_metrics['mae'].append(compute_mae(pred_frame, gt_frame))\n",
        "                    e2e_frame_metrics['psnr'].append(compute_psnr(pred_frame, gt_frame))\n",
        "                    e2e_frame_metrics['ssim'].append(compute_ssim(pred_frame, gt_frame))\n",
        "                \n",
        "                all_metrics['mse'].append(np.mean(e2e_frame_metrics['mse']))\n",
        "                all_metrics['mae'].append(np.mean(e2e_frame_metrics['mae']))\n",
        "                all_metrics['psnr'].append(np.mean(e2e_frame_metrics['psnr']))\n",
        "                all_metrics['ssim'].append(np.mean(e2e_frame_metrics['ssim']))\n",
        "                \n",
        "                e2e_traj_err = compute_trajectory_error(e2e_pred_eval, e2e_gt_eval)\n",
        "                all_metrics['trajectory_error'].append(e2e_traj_err['mean'])\n",
        "                \n",
        "                all_metrics['temporal_consistency_pred'].append(\n",
        "                    compute_temporal_consistency(e2e_pred_eval)\n",
        "                )\n",
        "                all_metrics['temporal_consistency_gt'].append(\n",
        "                    compute_temporal_consistency(e2e_gt_eval)\n",
        "                )\n",
        "                \n",
        "                sample_count += 1\n",
        "                pbar.update(1)\n",
        "    \n",
        "    pbar.close()\n",
        "    \n",
        "    return {\n",
        "        'e2e': all_metrics,\n",
        "        'planner': planner_metrics,\n",
        "        'refiner': refiner_metrics\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_statistics(values: List[float]) -> Dict[str, float]:\n",
        "    values = [v for v in values if not np.isnan(v) and np.isfinite(v)]\n",
        "    if len(values) == 0:\n",
        "        return {'mean': float('nan'), 'std': float('nan'), 'min': float('nan'), 'max': float('nan')}\n",
        "    \n",
        "    return {\n",
        "        'mean': float(np.mean(values)),\n",
        "        'std': float(np.std(values)),\n",
        "        'min': float(np.min(values)),\n",
        "        'max': float(np.max(values))\n",
        "    }\n",
        "\n",
        "\n",
        "def save_results(metrics: Dict[str, List[float]], output_path: str, config: Dict):\n",
        "    results = {'config': config, 'metrics': {}, 'statistics': {}}\n",
        "    \n",
        "    for key, values in metrics.items():\n",
        "        results['metrics'][key] = values\n",
        "        results['statistics'][key] = compute_statistics(values)\n",
        "    \n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    \n",
        "    print(f\"Results saved to {output_path}\")\n",
        "\n",
        "\n",
        "def print_summary(metrics: Dict[str, List[float]], title: str = \"Evaluation Results\"):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{title}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    for key, values in metrics.items():\n",
        "        stats = compute_statistics(values)\n",
        "        print(f\"\\n{key.upper()}:\")\n",
        "        print(f\"  Mean:   {stats['mean']:.4f}\")\n",
        "        print(f\"  Std:    {stats['std']:.4f}\")\n",
        "        print(f\"  Min:    {stats['min']:.4f}\")\n",
        "        print(f\"  Max:    {stats['max']:.4f}\")\n",
        "        print(f\"  Count:  {len(values)}\")\n",
        "\n",
        "\n",
        "print(\"Evaluation functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Load Models ======\n",
        "device = torch.device(DEVICE)\n",
        "# Set gpu number as 1\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Planner\n",
        "config_planner = ConfigPlanner()\n",
        "config_planner.target_res = LATENT_RES\n",
        "config_planner.max_seq_len = 100\n",
        "\n",
        "planner = LatentPlanner(config_planner).to(device)\n",
        "planner_state = torch.load(PLANNER_CKPT, map_location='cpu')\n",
        "\n",
        "model_state = planner.state_dict()\n",
        "checkpoint_state = planner_state\n",
        "\n",
        "if 'pe.pe' in checkpoint_state and 'pe.pe' in model_state:\n",
        "    if checkpoint_state['pe.pe'].shape != model_state['pe.pe'].shape:\n",
        "        print(f\"Warning: PositionalEncoding size mismatch. \"\n",
        "              f\"Checkpoint: {checkpoint_state['pe.pe'].shape}, \"\n",
        "              f\"Model: {model_state['pe.pe'].shape}\")\n",
        "        print(\"Skipping PE loading (will use model's initialized PE)\")\n",
        "        checkpoint_state = {k: v for k, v in checkpoint_state.items() if not k.startswith('pe.')}\n",
        "\n",
        "planner.load_state_dict(checkpoint_state, strict=False)\n",
        "planner.eval()\n",
        "print(f\"Loaded Planner: {PLANNER_CKPT}\")\n",
        "\n",
        "refiner = AsymmetricUNet(\n",
        "    in_channels=3,\n",
        "    out_channels=3,\n",
        "    model_channels=REF_MODEL_CHANNELS,\n",
        "    channel_mult=REF_CHANNEL_MULT,\n",
        "    num_res_blocks=REF_NUM_RES_BLOCKS,\n",
        ").to(device)\n",
        "\n",
        "refiner_state = torch.load(REFINER_CKPT, map_location='cpu')\n",
        "refiner.load_state_dict(refiner_state, strict=False)\n",
        "refiner.eval()\n",
        "print(f\"Loaded Refiner: {REFINER_CKPT}\")\n",
        "\n",
        "scheduler = NoiseScheduler(device=device)\n",
        "print(\"Models loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    max_len = max(item[\"length\"] for item in batch)\n",
        "    B = len(batch)\n",
        "    sample_seq = batch[0][\"seq\"]\n",
        "    C, H, W = sample_seq.shape[1:]\n",
        "    \n",
        "    seq = torch.zeros(B, max_len, C, H, W, dtype=sample_seq.dtype)\n",
        "    attn = torch.zeros(B, max_len, dtype=batch[0][\"attention_mask\"].dtype)\n",
        "    lengths = torch.zeros(B, dtype=torch.long)\n",
        "    paths = []\n",
        "    \n",
        "    for i, item in enumerate(batch):\n",
        "        l = item[\"length\"]\n",
        "        seq[i, :l] = item[\"seq\"]\n",
        "        attn[i, :l] = item[\"attention_mask\"]\n",
        "        lengths[i] = l\n",
        "        paths.append(item[\"path\"])\n",
        "    \n",
        "    return {\"seq\": seq, \"attention_mask\": attn, \"lengths\": lengths, \"paths\": paths}\n",
        "\n",
        "lowres_dataset = LowResVideoDataset(\n",
        "    root=LOWRES_ROOT,\n",
        "    split=SPLIT,\n",
        "    target_res=LATENT_RES,\n",
        "    max_seq_len=100\n",
        ")\n",
        "\n",
        "lowres_dataloader = DataLoader(\n",
        "    lowres_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "print(f\"Loaded low-res dataset: {len(lowres_dataset)} samples\")\n",
        "\n",
        "highres_dataset = None\n",
        "highres_dataloader = None\n",
        "\n",
        "if EVAL_MODE in ['refiner', 'end2end', 'all']:\n",
        "    try:\n",
        "        highres_dataset = LowResVideoDataset(\n",
        "            root=HIGHRES_ROOT,\n",
        "            split=SPLIT,\n",
        "            target_res=HIGH_RES,\n",
        "            max_seq_len=100\n",
        "        )\n",
        "        print(f\"Loaded high-res dataset from {HIGHRES_ROOT}: {len(highres_dataset)} samples\")\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Warning: Could not load high-res dataset from {HIGHRES_ROOT}\")\n",
        "        print(f\"  Error: {e}\")\n",
        "        print(f\"  Will use upscaled low-res data as GT\")\n",
        "        highres_dataset = lowres_dataset\n",
        "    \n",
        "    highres_dataloader = DataLoader(\n",
        "        highres_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "print(\"Datasets loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for cond_frames_val in COND_FRAMES_LIST:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating with cond_frames={cond_frames_val}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    cond_results = {}\n",
        "    \n",
        "    if EVAL_MODE in ['planner', 'all']:\n",
        "        print(\"\\n--- Planner Evaluation ---\")\n",
        "        planner_metrics = evaluate_planner(\n",
        "            planner, lowres_dataloader, device,\n",
        "            cond_frames=cond_frames_val,\n",
        "            max_samples=MAX_SAMPLES\n",
        "        )\n",
        "        cond_results['planner'] = planner_metrics\n",
        "        print_summary(planner_metrics, f\"Planner (cond_frames={cond_frames_val})\")\n",
        "        \n",
        "        save_results(\n",
        "            planner_metrics,\n",
        "            os.path.join(OUTPUT_DIR, f'planner_cond{cond_frames_val}.json'),\n",
        "            {'cond_frames': cond_frames_val, 'mode': 'planner'}\n",
        "        )\n",
        "    \n",
        "    if EVAL_MODE in ['refiner', 'all']:\n",
        "        print(\"\\n--- Refiner Evaluation ---\")\n",
        "        if highres_dataset is None or highres_dataset.target_res != HIGH_RES:\n",
        "            print(\"  Note: Using upscaled low-res as GT\")\n",
        "        \n",
        "        refiner_metrics = evaluate_refiner(\n",
        "            refiner, scheduler, lowres_dataloader, highres_dataloader,\n",
        "            device,\n",
        "            high_res=HIGH_RES,\n",
        "            latent_res=LATENT_RES,\n",
        "            k_step=K_STEP,\n",
        "            t_start_frac=T_START_FRAC,\n",
        "            batch_frames=REFINER_BATCH_FRAMES,\n",
        "            max_samples=MAX_SAMPLES\n",
        "        )\n",
        "        cond_results['refiner'] = refiner_metrics\n",
        "        print_summary(refiner_metrics, f\"Refiner (cond_frames={cond_frames_val})\")\n",
        "        \n",
        "        save_results(\n",
        "            refiner_metrics,\n",
        "            os.path.join(OUTPUT_DIR, f'refiner_cond{cond_frames_val}.json'),\n",
        "            {'cond_frames': cond_frames_val, 'mode': 'refiner'}\n",
        "        )\n",
        "    \n",
        "    if EVAL_MODE in ['end2end', 'all']:\n",
        "        print(\"\\n--- End-to-End Evaluation (with stage-wise errors) ---\")\n",
        "        e2e_results = evaluate_end2end(\n",
        "            planner, refiner, scheduler,\n",
        "            lowres_dataloader, highres_dataloader,\n",
        "            device,\n",
        "            cond_frames=cond_frames_val,\n",
        "            high_res=HIGH_RES,\n",
        "            latent_res=LATENT_RES,\n",
        "            k_step=K_STEP,\n",
        "            t_start_frac=T_START_FRAC,\n",
        "            batch_frames=REFINER_BATCH_FRAMES,\n",
        "            max_samples=MAX_SAMPLES\n",
        "        )\n",
        "        \n",
        "        e2e_metrics = e2e_results['e2e']\n",
        "        planner_stage_metrics = e2e_results['planner']\n",
        "        refiner_stage_metrics = e2e_results['refiner']\n",
        "        \n",
        "        cond_results['end2end'] = e2e_metrics\n",
        "        cond_results['planner_stage'] = planner_stage_metrics\n",
        "        cond_results['refiner_stage'] = refiner_stage_metrics\n",
        "        \n",
        "        print_summary(e2e_metrics, f\"End-to-End (cond_frames={cond_frames_val})\")\n",
        "        print_summary(planner_stage_metrics, f\"Planner Stage Error (cond_frames={cond_frames_val})\")\n",
        "        print_summary(refiner_stage_metrics, f\"Refiner Stage Error (cond_frames={cond_frames_val})\")\n",
        "        \n",
        "        save_results(\n",
        "            e2e_metrics,\n",
        "            os.path.join(OUTPUT_DIR, f'end2end_cond{cond_frames_val}.json'),\n",
        "            {'cond_frames': cond_frames_val, 'mode': 'end2end'}\n",
        "        )\n",
        "        \n",
        "        save_results(\n",
        "            planner_stage_metrics,\n",
        "            os.path.join(OUTPUT_DIR, f'planner_stage_cond{cond_frames_val}.json'),\n",
        "            {'cond_frames': cond_frames_val, 'mode': 'planner_stage'}\n",
        "        )\n",
        "        \n",
        "        save_results(\n",
        "            refiner_stage_metrics,\n",
        "            os.path.join(OUTPUT_DIR, f'refiner_stage_cond{cond_frames_val}.json'),\n",
        "            {'cond_frames': cond_frames_val, 'mode': 'refiner_stage'}\n",
        "        )\n",
        "    \n",
        "    all_results[f'cond_frames_{cond_frames_val}'] = cond_results\n",
        "\n",
        "summary_path = os.path.join(OUTPUT_DIR, 'summary_all.json')\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "print(f\"\\nSummary saved to {summary_path}\")\n",
        "\n",
        "print(\"\\nEvaluation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESULT_PATHS = [\n",
        "    '/workspace/evaluation_results/end2end_cond1.json',\n",
        "    '/workspace/evaluation_results/end2end_cond3.json',\n",
        "    '/workspace/evaluation_results/end2end_cond5.json',\n",
        "    '/workspace/evaluation_results/end2end_cond10.json',\n",
        "]\n",
        "\n",
        "print(f\"Will load {len(RESULT_PATHS)} result files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "all_data = []\n",
        "cond_frames_list = []\n",
        "\n",
        "for result_path in RESULT_PATHS:\n",
        "    if not os.path.exists(result_path):\n",
        "        print(f\"Warning: File not found: {result_path}\")\n",
        "        continue\n",
        "    \n",
        "    try:\n",
        "        with open(result_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            all_data.append(data)\n",
        "            cond_frames = data['config'].get('cond_frames', None)\n",
        "            if cond_frames is not None:\n",
        "                cond_frames_list.append(cond_frames)\n",
        "            print(f\"Loaded: {result_path} (cond_frames={cond_frames})\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {result_path}: {e}\")\n",
        "\n",
        "cond_frames_list = sorted(set(cond_frames_list))\n",
        "print(f\"\\nTotal condition frames found: {cond_frames_list}\")\n",
        "print(f\"Total result files loaded: {len(all_data)}\")\n",
        "\n",
        "metrics_by_cond = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "for data in all_data:\n",
        "    cond_frames = data['config'].get('cond_frames', None)\n",
        "    if cond_frames is None:\n",
        "        continue\n",
        "    \n",
        "    metrics = data.get('metrics', {})\n",
        "    for metric_name, values in metrics.items():\n",
        "        if isinstance(values, list) and len(values) > 0:\n",
        "            metrics_by_cond[metric_name][cond_frames].extend(values)\n",
        "\n",
        "print(\"\\nMetrics collected:\")\n",
        "for metric_name in sorted(metrics_by_cond.keys()):\n",
        "    cond_count = len(metrics_by_cond[metric_name])\n",
        "    total_samples = sum(len(v) for v in metrics_by_cond[metric_name].values())\n",
        "    print(f\"  - {metric_name}: {cond_count} cond_frames, {total_samples} total samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "metric_names = ['mse', 'mae', 'psnr', 'ssim', 'trajectory_error']\n",
        "n_metrics = len(metric_names)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, metric_name in enumerate(metric_names):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    if metric_name not in metrics_by_cond:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        continue\n",
        "    \n",
        "    data_to_plot = []\n",
        "    labels = []\n",
        "    \n",
        "    for cond_frames in sorted(metrics_by_cond[metric_name].keys()):\n",
        "        values = metrics_by_cond[metric_name][cond_frames]\n",
        "        # Filter out NaN and inf values\n",
        "        values = [v for v in values if not (np.isnan(v) or np.isinf(v))]\n",
        "        if len(values) > 0:\n",
        "            data_to_plot.append(values)\n",
        "            labels.append(f'cond={cond_frames}')\n",
        "    \n",
        "    if len(data_to_plot) > 0:\n",
        "        bp = ax.boxplot(data_to_plot, labels=labels, patch_artist=True)\n",
        "        \n",
        "        # Color the boxes\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, len(bp['boxes'])))\n",
        "        for patch, color in zip(bp['boxes'], colors):\n",
        "            patch.set_facecolor(color)\n",
        "        \n",
        "        ax.set_title(f'{metric_name.upper()}', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no valid data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "# Remove empty subplot\n",
        "axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save to first result file's directory or current directory\n",
        "save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'metrics_boxplots.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Saved: {save_path}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot 2: Mean Metrics vs Condition Frames ======\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, metric_name in enumerate(metric_names):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    if metric_name not in metrics_by_cond:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        continue\n",
        "    \n",
        "    cond_frames_sorted = sorted(metrics_by_cond[metric_name].keys())\n",
        "    means = []\n",
        "    stds = []\n",
        "    \n",
        "    for cond_frames in cond_frames_sorted:\n",
        "        values = metrics_by_cond[metric_name][cond_frames]\n",
        "        values = [v for v in values if not (np.isnan(v) or np.isinf(v))]\n",
        "        if len(values) > 0:\n",
        "            means.append(np.mean(values))\n",
        "            stds.append(np.std(values))\n",
        "        else:\n",
        "            means.append(np.nan)\n",
        "            stds.append(np.nan)\n",
        "    \n",
        "    if len(means) > 0 and not all(np.isnan(means)):\n",
        "        ax.errorbar(cond_frames_sorted, means, yerr=stds, \n",
        "                   marker='o', markersize=8, capsize=5, capthick=2,\n",
        "                   linewidth=2, label='Mean  Std')\n",
        "        ax.set_title(f'{metric_name.upper()} vs Condition Frames', \n",
        "                    fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Condition Frames')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no valid data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "# Remove empty subplot\n",
        "axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'metrics_vs_cond_frames.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Saved: {save_path}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot 3: Statistics Summary Table ======\n",
        "\n",
        "# Compute statistics from loaded data\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY STATISTICS (Computed from loaded data)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for metric_name in metric_names:\n",
        "    print(f\"\\n{metric_name.upper()}:\")\n",
        "    print(f\"{'Cond Frames':<15} {'Mean':<15} {'Std':<15} {'Min':<15} {'Max':<15} {'Samples':<10}\")\n",
        "    print(\"-\" * 85)\n",
        "    \n",
        "    for cond_frames in sorted(cond_frames_list):\n",
        "        if metric_name in metrics_by_cond and cond_frames in metrics_by_cond[metric_name]:\n",
        "            values = metrics_by_cond[metric_name][cond_frames]\n",
        "            values = [v for v in values if not (np.isnan(v) or np.isinf(v))]\n",
        "            \n",
        "            if len(values) > 0:\n",
        "                mean_val = np.mean(values)\n",
        "                std_val = np.std(values)\n",
        "                min_val = np.min(values)\n",
        "                max_val = np.max(values)\n",
        "                n_samples = len(values)\n",
        "                \n",
        "                print(f\"{cond_frames:<15} {mean_val:<15.6f} {std_val:<15.6f} {min_val:<15.6f} {max_val:<15.6f} {n_samples:<10}\")\n",
        "            else:\n",
        "                print(f\"{cond_frames:<15} {'N/A':<15} {'N/A':<15} {'N/A':<15} {'N/A':<15} {'0':<10}\")\n",
        "        else:\n",
        "            print(f\"{cond_frames:<15} {'N/A':<15} {'N/A':<15} {'N/A':<15} {'N/A':<15} {'0':<10}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot 4: Heatmap of Mean Metrics ======\n",
        "\n",
        "# Prepare data for heatmap\n",
        "heatmap_data = []\n",
        "row_labels = []\n",
        "\n",
        "for metric_name in metric_names:\n",
        "    row = []\n",
        "    for cond_frames in sorted(cond_frames_list):\n",
        "        if metric_name in metrics_by_cond and cond_frames in metrics_by_cond[metric_name]:\n",
        "            values = metrics_by_cond[metric_name][cond_frames]\n",
        "            values = [v for v in values if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(values) > 0:\n",
        "                row.append(np.mean(values))\n",
        "            else:\n",
        "                row.append(np.nan)\n",
        "        else:\n",
        "            row.append(np.nan)\n",
        "    \n",
        "    if not all(np.isnan(row)):\n",
        "        heatmap_data.append(row)\n",
        "        row_labels.append(metric_name.upper())\n",
        "\n",
        "if len(heatmap_data) > 0:\n",
        "    heatmap_data = np.array(heatmap_data)\n",
        "    col_labels = [f'cond={cf}' for cf in sorted(cond_frames_list)]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    im = ax.imshow(heatmap_data, cmap='RdYlGn', aspect='auto')\n",
        "    \n",
        "    # Normalize for better visualization (invert for MSE, MAE, trajectory_error)\n",
        "    for i, metric_name in enumerate(metric_names):\n",
        "        if metric_name in ['mse', 'mae', 'trajectory_error']:\n",
        "            # Lower is better - invert colormap\n",
        "            pass\n",
        "    \n",
        "    ax.set_xticks(np.arange(len(col_labels)))\n",
        "    ax.set_yticks(np.arange(len(row_labels)))\n",
        "    ax.set_xticklabels(col_labels)\n",
        "    ax.set_yticklabels(row_labels)\n",
        "    \n",
        "    # Add text annotations\n",
        "    for i in range(len(row_labels)):\n",
        "        for j in range(len(col_labels)):\n",
        "            if not np.isnan(heatmap_data[i, j]):\n",
        "                text = ax.text(j, i, f'{heatmap_data[i, j]:.4f}',\n",
        "                             ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
        "    \n",
        "    ax.set_title('Mean Metrics Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
        "    plt.colorbar(im, ax=ax)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, 'metrics_heatmap.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data available for heatmap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot 5: Distribution Histograms ======\n",
        "\n",
        "# Plot histograms for key metrics\n",
        "key_metrics = ['psnr', 'ssim', 'trajectory_error']\n",
        "n_key = len(key_metrics)\n",
        "\n",
        "fig, axes = plt.subplots(1, n_key, figsize=(15, 5))\n",
        "\n",
        "for idx, metric_name in enumerate(key_metrics):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    if metric_name not in metrics_by_cond:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        continue\n",
        "    \n",
        "    for cond_frames in sorted(metrics_by_cond[metric_name].keys()):\n",
        "        values = metrics_by_cond[metric_name][cond_frames]\n",
        "        values = [v for v in values if not (np.isnan(v) or np.isinf(v))]\n",
        "        if len(values) > 0:\n",
        "            ax.hist(values, alpha=0.6, label=f'cond={cond_frames}', bins=15)\n",
        "    \n",
        "    ax.set_title(f'{metric_name.upper()} Distribution', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'metrics_distributions.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Saved: {save_path}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot 6: Temporal Consistency Comparison ======\n",
        "\n",
        "if 'temporal_consistency_pred' in metrics_by_cond and 'temporal_consistency_gt' in metrics_by_cond:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Predicted temporal consistency\n",
        "    cond_frames_sorted = sorted(metrics_by_cond['temporal_consistency_pred'].keys())\n",
        "    pred_means = []\n",
        "    pred_stds = []\n",
        "    gt_means = []\n",
        "    gt_stds = []\n",
        "    \n",
        "    for cond_frames in cond_frames_sorted:\n",
        "        pred_values = metrics_by_cond['temporal_consistency_pred'][cond_frames]\n",
        "        pred_values = [v for v in pred_values if not (np.isnan(v) or np.isinf(v))]\n",
        "        if len(pred_values) > 0:\n",
        "            pred_means.append(np.mean(pred_values))\n",
        "            pred_stds.append(np.std(pred_values))\n",
        "        else:\n",
        "            pred_means.append(np.nan)\n",
        "            pred_stds.append(np.nan)\n",
        "        \n",
        "        if cond_frames in metrics_by_cond['temporal_consistency_gt']:\n",
        "            gt_values = metrics_by_cond['temporal_consistency_gt'][cond_frames]\n",
        "            gt_values = [v for v in gt_values if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(gt_values) > 0:\n",
        "                gt_means.append(np.mean(gt_values))\n",
        "                gt_stds.append(np.std(gt_values))\n",
        "            else:\n",
        "                gt_means.append(np.nan)\n",
        "                gt_stds.append(np.nan)\n",
        "        else:\n",
        "            gt_means.append(np.nan)\n",
        "            gt_stds.append(np.nan)\n",
        "    \n",
        "    # Plot comparison\n",
        "    x = np.arange(len(cond_frames_sorted))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax1.bar(x - width/2, pred_means, width, yerr=pred_stds, label='Predicted', alpha=0.8)\n",
        "    ax1.bar(x + width/2, gt_means, width, yerr=gt_stds, label='GT', alpha=0.8)\n",
        "    ax1.set_xlabel('Condition Frames')\n",
        "    ax1.set_ylabel('Temporal Consistency')\n",
        "    ax1.set_title('Temporal Consistency: Predicted vs GT', fontweight='bold')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels([f'cond={cf}' for cf in cond_frames_sorted])\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Box plot comparison\n",
        "    pred_data = [metrics_by_cond['temporal_consistency_pred'][cf] \n",
        "                 for cf in cond_frames_sorted \n",
        "                 if cf in metrics_by_cond['temporal_consistency_pred']]\n",
        "    gt_data = [metrics_by_cond['temporal_consistency_gt'][cf] \n",
        "               for cf in cond_frames_sorted \n",
        "               if cf in metrics_by_cond['temporal_consistency_gt']]\n",
        "    \n",
        "    bp1 = ax2.boxplot(pred_data, positions=[i-0.2 for i in range(1, len(cond_frames_sorted)+1)], \n",
        "                      widths=0.35, patch_artist=True, labels=[f'cond={cf}' for cf in cond_frames_sorted])\n",
        "    bp2 = ax2.boxplot(gt_data, positions=[i+0.2 for i in range(1, len(cond_frames_sorted)+1)], \n",
        "                      widths=0.35, patch_artist=True)\n",
        "    \n",
        "    for patch in bp1['boxes']:\n",
        "        patch.set_facecolor('lightblue')\n",
        "    for patch in bp2['boxes']:\n",
        "        patch.set_facecolor('lightcoral')\n",
        "    \n",
        "    ax2.set_xlabel('Condition Frames')\n",
        "    ax2.set_ylabel('Temporal Consistency')\n",
        "    ax2.set_title('Temporal Consistency Distribution', fontweight='bold')\n",
        "    ax2.legend([bp1['boxes'][0], bp2['boxes'][0]], ['Predicted', 'GT'])\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, 'temporal_consistency_comparison.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Temporal consistency data not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Load Stage-wise Error Results ======\n",
        "STAGE_RESULT_PATHS = {\n",
        "    'planner': [],\n",
        "    'refiner': [],\n",
        "    'e2e': []\n",
        "}\n",
        "\n",
        "import glob\n",
        "for cond_frames in cond_frames_list:\n",
        "    planner_path = os.path.join(os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR, \n",
        "                                f'planner_stage_cond{cond_frames}.json')\n",
        "    refiner_path = os.path.join(os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR,\n",
        "                                f'refiner_stage_cond{cond_frames}.json')\n",
        "    e2e_path = os.path.join(os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR,\n",
        "                            f'end2end_cond{cond_frames}.json')\n",
        "    \n",
        "    if os.path.exists(planner_path):\n",
        "        STAGE_RESULT_PATHS['planner'].append(planner_path)\n",
        "    if os.path.exists(refiner_path):\n",
        "        STAGE_RESULT_PATHS['refiner'].append(refiner_path)\n",
        "    if os.path.exists(e2e_path):\n",
        "        STAGE_RESULT_PATHS['e2e'].append(e2e_path)\n",
        "\n",
        "print(\"Stage-wise result files:\")\n",
        "print(f\"  Planner: {len(STAGE_RESULT_PATHS['planner'])} files\")\n",
        "print(f\"  Refiner: {len(STAGE_RESULT_PATHS['refiner'])} files\")\n",
        "print(f\"  E2E: {len(STAGE_RESULT_PATHS['e2e'])} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Load and Organize Stage-wise Metrics ======\n",
        "\n",
        "stage_metrics = {\n",
        "    'planner': defaultdict(lambda: defaultdict(list)),\n",
        "    'refiner': defaultdict(lambda: defaultdict(list)),\n",
        "    'e2e': defaultdict(lambda: defaultdict(list))\n",
        "}\n",
        "\n",
        "# Load planner stage errors\n",
        "for file_path in STAGE_RESULT_PATHS['planner']:\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            cond_frames = data['config'].get('cond_frames', None)\n",
        "            if cond_frames is not None:\n",
        "                metrics = data.get('metrics', {})\n",
        "                for metric_name, values in metrics.items():\n",
        "                    if isinstance(values, list):\n",
        "                        stage_metrics['planner'][metric_name][cond_frames].extend(values)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "# Load refiner stage errors\n",
        "for file_path in STAGE_RESULT_PATHS['refiner']:\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            cond_frames = data['config'].get('cond_frames', None)\n",
        "            if cond_frames is not None:\n",
        "                metrics = data.get('metrics', {})\n",
        "                for metric_name, values in metrics.items():\n",
        "                    if isinstance(values, list):\n",
        "                        stage_metrics['refiner'][metric_name][cond_frames].extend(values)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "# Load e2e errors (from existing end2end files)\n",
        "for file_path in STAGE_RESULT_PATHS['e2e']:\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            cond_frames = data['config'].get('cond_frames', None)\n",
        "            if cond_frames is not None:\n",
        "                metrics = data.get('metrics', {})\n",
        "                for metric_name, values in metrics.items():\n",
        "                    if isinstance(values, list):\n",
        "                        stage_metrics['e2e'][metric_name][cond_frames].extend(values)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "print(\"\\nStage-wise metrics loaded:\")\n",
        "for stage in ['planner', 'refiner', 'e2e']:\n",
        "    print(f\"\\n{stage.upper()}:\")\n",
        "    for metric_name in sorted(stage_metrics[stage].keys()):\n",
        "        cond_count = len(stage_metrics[stage][metric_name])\n",
        "        total_samples = sum(len(v) for v in stage_metrics[stage][metric_name].values())\n",
        "        print(f\"  - {metric_name}: {cond_count} cond_frames, {total_samples} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot: Stage-wise Error Comparison ======\n",
        "\n",
        "key_metrics = ['mse', 'mae', 'psnr', 'ssim', 'trajectory_error']\n",
        "n_metrics = len(key_metrics)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, metric_name in enumerate(key_metrics):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    stages_data = {}\n",
        "    for stage in ['planner', 'refiner', 'e2e']:\n",
        "        if metric_name in stage_metrics[stage]:\n",
        "            cond_frames_sorted = sorted(stage_metrics[stage][metric_name].keys())\n",
        "            means = []\n",
        "            stds = []\n",
        "            \n",
        "            for cond_frames in cond_frames_sorted:\n",
        "                values = stage_metrics[stage][metric_name][cond_frames]\n",
        "                values = [v for v in values if not (np.isnan(v) or np.isinf(v))]\n",
        "                if len(values) > 0:\n",
        "                    means.append(np.mean(values))\n",
        "                    stds.append(np.std(values))\n",
        "                else:\n",
        "                    means.append(np.nan)\n",
        "                    stds.append(np.nan)\n",
        "            \n",
        "            if len(means) > 0 and not all(np.isnan(means)):\n",
        "                stages_data[stage] = {\n",
        "                    'cond_frames': cond_frames_sorted,\n",
        "                    'means': means,\n",
        "                    'stds': stds\n",
        "                }\n",
        "    \n",
        "    # Plot\n",
        "    if len(stages_data) > 0:\n",
        "        colors = {'planner': 'blue', 'refiner': 'green', 'e2e': 'red'}\n",
        "        markers = {'planner': 'o', 'refiner': 's', 'e2e': '^'}\n",
        "        labels = {'planner': 'Planner Stage', 'refiner': 'Refiner Stage', 'e2e': 'End-to-End'}\n",
        "        \n",
        "        for stage in ['planner', 'refiner', 'e2e']:\n",
        "            if stage in stages_data:\n",
        "                data = stages_data[stage]\n",
        "                ax.errorbar(data['cond_frames'], data['means'], yerr=data['stds'],\n",
        "                           marker=markers[stage], markersize=8, capsize=5, capthick=2,\n",
        "                           linewidth=2, label=labels[stage], color=colors[stage], alpha=0.8)\n",
        "        \n",
        "        ax.set_title(f'{metric_name.upper()} - Stage Comparison', fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Condition Frames')\n",
        "        ax.set_ylabel('Value')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "# Remove empty subplot\n",
        "axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'stage_wise_error_comparison.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Saved: {save_path}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Plot: Error Contribution Analysis ======\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, metric_name in enumerate(key_metrics):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    if metric_name not in stage_metrics['e2e']:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no E2E data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        continue\n",
        "    \n",
        "    cond_frames_sorted = sorted(stage_metrics['e2e'][metric_name].keys())\n",
        "    \n",
        "    planner_contrib = []\n",
        "    refiner_contrib = []\n",
        "    e2e_values = []\n",
        "    \n",
        "    for cond_frames in cond_frames_sorted:\n",
        "        e2e_vals = stage_metrics['e2e'][metric_name][cond_frames]\n",
        "        e2e_vals = [v for v in e2e_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "        if len(e2e_vals) == 0:\n",
        "            continue\n",
        "        \n",
        "        e2e_mean = np.mean(e2e_vals)\n",
        "        e2e_values.append(e2e_mean)\n",
        "        \n",
        "        if metric_name in stage_metrics['planner'] and cond_frames in stage_metrics['planner'][metric_name]:\n",
        "            planner_vals = stage_metrics['planner'][metric_name][cond_frames]\n",
        "            planner_vals = [v for v in planner_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(planner_vals) > 0:\n",
        "                planner_mean = np.mean(planner_vals)\n",
        "                if metric_name in ['mse', 'mae', 'trajectory_error']:\n",
        "                    contrib = planner_mean / (e2e_mean + 1e-8) * 100\n",
        "                else:\n",
        "                    contrib = (1 - planner_mean / (e2e_mean + 1e-8)) * 100\n",
        "                planner_contrib.append(contrib)\n",
        "            else:\n",
        "                planner_contrib.append(0)\n",
        "        else:\n",
        "            planner_contrib.append(0)\n",
        "        \n",
        "        if metric_name in stage_metrics['refiner'] and cond_frames in stage_metrics['refiner'][metric_name]:\n",
        "            refiner_vals = stage_metrics['refiner'][metric_name][cond_frames]\n",
        "            refiner_vals = [v for v in refiner_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(refiner_vals) > 0:\n",
        "                refiner_mean = np.mean(refiner_vals)\n",
        "                if metric_name in ['mse', 'mae', 'trajectory_error']:\n",
        "                    contrib = refiner_mean / (e2e_mean + 1e-8) * 100\n",
        "                else:\n",
        "                    contrib = (1 - refiner_mean / (e2e_mean + 1e-8)) * 100\n",
        "                refiner_contrib.append(contrib)\n",
        "            else:\n",
        "                refiner_contrib.append(0)\n",
        "        else:\n",
        "            refiner_contrib.append(0)\n",
        "    \n",
        "    if len(e2e_values) > 0:\n",
        "        x = np.arange(len(cond_frames_sorted))\n",
        "        width = 0.25\n",
        "        \n",
        "        ax.bar(x - width, planner_contrib, width, label='Planner Contribution', color='blue', alpha=0.7)\n",
        "        ax.bar(x, refiner_contrib, width, label='Refiner Contribution', color='green', alpha=0.7)\n",
        "        ax.bar(x + width, [100 - p - r for p, r in zip(planner_contrib, refiner_contrib)], \n",
        "               width, label='Other/Interaction', color='gray', alpha=0.7)\n",
        "        \n",
        "        ax.set_title(f'{metric_name.upper()} - Error Contribution by Stage', fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Condition Frames')\n",
        "        ax.set_ylabel('Contribution (%)')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels([f'cond={cf}' for cf in cond_frames_sorted])\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "        ax.set_ylim([0, 100])\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, f'{metric_name}\\n(no valid data)', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "axes[-1].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "save_dir = os.path.dirname(RESULT_PATHS[0]) if RESULT_PATHS else OUTPUT_DIR\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "save_path = os.path.join(save_dir, 'error_contribution_by_stage.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Saved: {save_path}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== Table: Stage-wise Error Summary ======\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"STAGE-WISE ERROR SUMMARY\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for metric_name in key_metrics:\n",
        "    print(f\"\\n{metric_name.upper()}:\")\n",
        "    print(f\"{'Cond':<8} {'Planner Stage':<20} {'Refiner Stage':<20} {'End-to-End':<20} {'PlannerRefiner':<20}\")\n",
        "    print(f\"{'Frames':<8} {'Mean  Std':<20} {'Mean  Std':<20} {'Mean  Std':<20} {'Error Increase':<20}\")\n",
        "    print(\"-\" * 100)\n",
        "    \n",
        "    all_cond_frames = set()\n",
        "    for stage in ['planner', 'refiner', 'e2e']:\n",
        "        if metric_name in stage_metrics[stage]:\n",
        "            all_cond_frames.update(stage_metrics[stage][metric_name].keys())\n",
        "    \n",
        "    for cond_frames in sorted(all_cond_frames):\n",
        "        planner_str = \"N/A\"\n",
        "        refiner_str = \"N/A\"\n",
        "        e2e_str = \"N/A\"\n",
        "        increase_str = \"N/A\"\n",
        "        \n",
        "        # Planner\n",
        "        if metric_name in stage_metrics['planner'] and cond_frames in stage_metrics['planner'][metric_name]:\n",
        "            planner_vals = stage_metrics['planner'][metric_name][cond_frames]\n",
        "            planner_vals = [v for v in planner_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(planner_vals) > 0:\n",
        "                planner_mean = np.mean(planner_vals)\n",
        "                planner_std = np.std(planner_vals)\n",
        "                planner_str = f\"{planner_mean:.4f}  {planner_std:.4f}\"\n",
        "        \n",
        "        # Refiner\n",
        "        if metric_name in stage_metrics['refiner'] and cond_frames in stage_metrics['refiner'][metric_name]:\n",
        "            refiner_vals = stage_metrics['refiner'][metric_name][cond_frames]\n",
        "            refiner_vals = [v for v in refiner_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(refiner_vals) > 0:\n",
        "                refiner_mean = np.mean(refiner_vals)\n",
        "                refiner_std = np.std(refiner_vals)\n",
        "                refiner_str = f\"{refiner_mean:.4f}  {refiner_std:.4f}\"\n",
        "        \n",
        "        # E2E\n",
        "        if metric_name in stage_metrics['e2e'] and cond_frames in stage_metrics['e2e'][metric_name]:\n",
        "            e2e_vals = stage_metrics['e2e'][metric_name][cond_frames]\n",
        "            e2e_vals = [v for v in e2e_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            if len(e2e_vals) > 0:\n",
        "                e2e_mean = np.mean(e2e_vals)\n",
        "                e2e_std = np.std(e2e_vals)\n",
        "                e2e_str = f\"{e2e_mean:.4f}  {e2e_std:.4f}\"\n",
        "        \n",
        "        # Planner  Refiner \n",
        "        if planner_str != \"N/A\" and refiner_str != \"N/A\":\n",
        "            planner_vals = stage_metrics['planner'][metric_name][cond_frames]\n",
        "            planner_vals = [v for v in planner_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            refiner_vals = stage_metrics['refiner'][metric_name][cond_frames]\n",
        "            refiner_vals = [v for v in refiner_vals if not (np.isnan(v) or np.isinf(v))]\n",
        "            \n",
        "            if len(planner_vals) > 0 and len(refiner_vals) > 0:\n",
        "                planner_mean = np.mean(planner_vals)\n",
        "                refiner_mean = np.mean(refiner_vals)\n",
        "                \n",
        "                if metric_name in ['mse', 'mae', 'trajectory_error']:\n",
        "                    increase = refiner_mean - planner_mean\n",
        "                    increase_str = f\"+{increase:.4f}\"\n",
        "                else:\n",
        "                    decrease = planner_mean - refiner_mean\n",
        "                    increase_str = f\"{decrease:.4f}\"\n",
        "        \n",
        "        print(f\"{cond_frames:<8} {planner_str:<20} {refiner_str:<20} {e2e_str:<20} {increase_str:<20}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
